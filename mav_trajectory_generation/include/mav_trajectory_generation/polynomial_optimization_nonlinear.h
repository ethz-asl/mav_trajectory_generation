/*
 * Copyright (c) 2016, Markus Achtelik, ASL, ETH Zurich, Switzerland
 * Copyright (c) 2016, Michael Burri, ASL, ETH Zurich, Switzerland
 * Copyright (c) 2016, Helen Oleynikova, ASL, ETH Zurich, Switzerland
 * Copyright (c) 2016, Rik BÃ¤hnemann, ASL, ETH Zurich, Switzerland
 * Copyright (c) 2016, Marija Popovic, ASL, ETH Zurich, Switzerland
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef MAV_TRAJECTORY_GENERATION_POLYNOMIAL_OPTIMIZATION_NONLINEAR_H_
#define MAV_TRAJECTORY_GENERATION_POLYNOMIAL_OPTIMIZATION_NONLINEAR_H_

#include <memory>
#include <nlopt.hpp>

#include "mav_trajectory_generation/polynomial_optimization_linear.h"

namespace mav_trajectory_generation {

constexpr double kOptimizationTimeLowerBound = 0.1;

// Class holding all important parameters for nonlinear optimization.
struct NonlinearOptimizationParameters {
  // Default parameters should be reasonable enough to use without further
  // fine-tuning.

  // Stopping criteria, if objective function changes less than absolute value.
  // Disabled if negative.
  double f_abs = -1;

  // Stopping criteria, if objective function changes less than relative value.
  // Disabled if negative.
  double f_rel = 0.05;

  // Stopping criteria, if state changes less than relative value.
  // Disabled if negative.
  double x_rel = -1;

  // Stopping criteria, if state changes less than absolute value.
  // Disabled if negative.
  double x_abs = -1;

  // Determines a fraction of the initial guess as initial step size.
  // Heuristic value if negative.
  double initial_stepsize_rel = 0.1;

  // Absolute tolerance, within an equality constraint is considered as met.
  double equality_constraint_tolerance = 1.0e-3;

  // Absolute tolerance, within an inequality constraint is considered as met.
  double inequality_constraint_tolerance = 0.1;

  // Maximum number of iterations. Disabled if negative.
  int max_iterations = 3000;

  // Penalty for the segment time.
  double time_penalty = 500.0;

  // Optimization algorithm used by nlopt, see
  // http://ab-initio.mit.edu/wiki/index.php/NLopt_Algorithms
  // Previous value was nlopt::LN_SBPLX, but we found that BOBYQA has slightly
  // better convergence and lower run-time in the unit tests.
  nlopt::algorithm algorithm = nlopt::LN_BOBYQA;

  // Random seed, if an optimization algorithm involving random numbers
  // is used (e.g. nlopt::GN_ISRES).
  // If set to a value < 0, a "random" (getTimeofday) value for the seed
  // is chosen.
  int random_seed = 0;

  // Decide whether to use soft constraints.
  bool use_soft_constraints = true;

  // Weights the relative violation of a soft constraint.
  double soft_constraint_weight = 100.0;

  enum TimeAllocMethod {
    kSquaredTime,
    kRichterTime,
    kMellingerOuterLoop,
    kSquaredTimeAndConstraints,
    kRichterTimeAndConstraints,
    kUnknown
  } time_alloc_method = kSquaredTimeAndConstraints;

  bool print_debug_info = false;
  bool print_debug_info_time_allocation = false;
};

struct OptimizationInfo {
  int n_iterations = 0;
  int stopping_reason = nlopt::FAILURE;
  double cost_trajectory = 0.0;
  double cost_time = 0.0;
  double cost_soft_constraints = 0.0;
  double optimization_time = 0.0;
  std::map<int, Extremum> maxima;
};

std::ostream& operator<<(std::ostream& stream, const OptimizationInfo& val);

// Implements a nonlinear optimization of the unconstrained optimization
// of paths consisting of polynomial segments as described in [1]
// [1]: Polynomial Trajectory Planning for Aggressive Quadrotor Flight in Dense
// Indoor Environments.
// Charles Richter, Adam Bry, and Nicholas Roy. In ISRR 2013
// _N specifies the number of coefficients for the underlying polynomials.
template <int _N = 10>
class PolynomialOptimizationNonLinear {
  static_assert(_N % 2 == 0, "The number of coefficients has to be even.");

 public:
  enum { N = _N };

  // Sets up the nonlinear optimization problem.
  // Input: dimension = Spatial dimension of the problem. Usually 1 or 3.
  // Input: parameters = Parameters for the optimization problem.
  // Input: optimize_time_only = Specifies whether the optimization is run
  // over the segment times only.
  // If true, only the segment times are optimization parameters, and the
  // remaining free parameters are found by solving the linear optimization
  // problem with the given segment times in every iteration.
  // If false, both segment times and free derivatives become optimization
  // variables. The latter case is theoretically correct, but may result in
  // more iterations.
  PolynomialOptimizationNonLinear(
      size_t dimension, const NonlinearOptimizationParameters& parameters);

  // Sets up the optimization problem from a vector of Vertex objects and
  // a vector of times between the vertices.
  // Input: vertices = Vector containing the vertices defining the support
  // points and constraints of the path.
  // Input: segment_times = Vector containing an initial guess of the time
  // between two vertices. Thus, its size is size(vertices) - 1.
  // Input: derivative_to_optimize = Specifies the derivative of which the
  // cost is optimized.
  bool setupFromVertices(
      const Vertex::Vector& vertices, const std::vector<double>& segment_times,
      int derivative_to_optimize =
          PolynomialOptimization<N>::kHighestDerivativeToOptimize);

  // Adds a constraint for the maximum of magnitude to the optimization
  // problem.
  // Input: derivative_order = Order of the derivative, for which the
  // constraint should be checked. Usually velocity (=1) or acceleration (=2).
  // maximum_value = Maximum magnitude of the specified derivative.
  bool addMaximumMagnitudeConstraint(int derivative_order,
                                     double maximum_value);

  // Solves the linear optimization problem according to [1].
  // The solver is re-used for every dimension, which means:
  //  - segment times are equal for each dimension.
  //  - each dimension has the same type/set of constraints. Their values can of
  // course differ.
  bool solveLinear();

  // Runs the optimization until one of the stopping criteria in
  // NonlinearOptimizationParameters and the constraints are met.
  int optimize();

  // Get the resulting trajectory out -- prefer this as the main method
  // to get the results of the optimization, over getting the reference
  // to the linear optimizer.
  void getTrajectory(Trajectory* trajectory) const {
    poly_opt_.getTrajectory(trajectory);
  }

  // Returns a const reference to the underlying linear optimization
  // object.
  const PolynomialOptimization<N>& getPolynomialOptimizationRef() const {
    return poly_opt_;
  }

  // Returns a non-const reference to the underlying linear optimization
  // object.
  PolynomialOptimization<N>& getPolynomialOptimizationRef() {
    return poly_opt_;
  }

  OptimizationInfo getOptimizationInfo() const { return optimization_info_; }

  // Functions for optimization, but may be useful for diagnostics outside.
  // Gets the trajectory cost (same as the cost in the linear problem).
  double getCost() const;

  // Gets the cost including the soft constraints and time costs, should be
  // the same cost function as used in the full optimization. Returns the same
  // metrics regardless of time estimation method set.
  double getTotalCostWithSoftConstraints() const;

  void scaleSegmentTimesWithViolation();

 private:
  // Holds the data for constraint evaluation, since these methods are
  // static.
  struct ConstraintData {
    PolynomialOptimizationNonLinear<N>* this_object;
    int derivative;
    double value;
  };

  // Objective function for the time-only version.
  // Input: segment_times = Segment times in the current iteration.
  // Input: gradient = Gradient of the objective function w.r.t. changes of
  // parameters. We can't compute the gradient analytically here.
  // Thus, only gradient-free optimization methods are possible.
  // Input: Custom data pointer = In our case, it's an ConstraintData object.
  // Output: Cost = based on the parameters passed in.
  static double objectiveFunctionTime(const std::vector<double>& segment_times,
                                      std::vector<double>& gradient,
                                      void* data);

  // Objective function for the time-only Mellinger Outer Loop.
  // Input: segment_times = Segment times in the current iteration.
  // Input: gradient = Gradient of the objective function w.r.t. changes of
  // parameters. We can't compute the gradient analytically here.
  // Thus, only gradient-free optimization methods are possible.
  // Input: Custom data pointer = In our case, it's an ConstraintData object.
  // Output: Cost = based on the parameters passed in.
  static double objectiveFunctionTimeMellingerOuterLoop(
      const std::vector<double>& segment_times, std::vector<double>& gradient,
      void* data);

  // Objective function for the version optimizing segment times and free
  // derivatives.
  // Input: optimization_variables = Optimization variables times in the
  // current iteration.
  // The variables (time, derivatives) are stacked as follows: [segment_times
  // derivatives_dim_0 ... derivatives_dim_N]
  // Input: gradient = Gradient of the objective function wrt. changes of
  // parameters. We can't compute the gradient analytically here.
  // Thus, only gradient free optimization methods are possible.
  // Input: data = Custom data pointer. In our case, it's an ConstraintData
  // object.
  // Output: Cost based on the parameters passed in.
  static double objectiveFunctionTimeAndConstraints(
      const std::vector<double>& optimization_variables,
      std::vector<double>& gradient, void* data);

  // Evaluates the maximum magnitude constraint at the current value of
  // the optimization variables.
  // All input parameters are ignored, all information is contained in data.
  static double evaluateMaximumMagnitudeConstraint(
      const std::vector<double>& optimization_variables,
      std::vector<double>& gradient, void* data);

  // Does the actual optimization work for the time-only version.
  int optimizeTime();
  int optimizeTimeMellingerOuterLoop();

  // Does the actual optimization work for the full optimization version.
  int optimizeTimeAndFreeConstraints();

  // Evaluates the maximum magnitude constraints as soft constraints and
  // returns a cost, depending on the violation of the constraints.
  // cost_i = min(maximum_cost, exp(abs_violation_i / max_allowed_i * weight))
  //  cost = sum(cost_i)
  // Input: inequality_constraints = Vector of ConstraintData shared_ptrs,
  // describing the constraints.
  // Input: weight = Multiplicative weight of the constraint violation.
  // Input: maximum_cost = Upper bound of the cost. Necessary, since exp of a
  // high violation can end up in inf.
  // Output: Sum of the costs per constraint.
  double evaluateMaximumMagnitudeAsSoftConstraint(
      const std::vector<std::shared_ptr<ConstraintData> >&
          inequality_constraints,
      double weight, double maximum_cost = 1.0e12) const;

  // Set lower and upper bounds on the optimization parameters
  void setFreeEndpointDerivativeHardConstraints(
      const Vertex::Vector& vertices, std::vector<double>* lower_bounds,
      std::vector<double>* upper_bounds);

  // Computes the gradients by doing forward difference!
  double getCostAndGradientMellinger(std::vector<double>* gradients);

  // Computes the total trajectory time.
  static double computeTotalTrajectoryTime(
      const std::vector<double>& segment_times);

  // nlopt optimization object.
  std::shared_ptr<nlopt::opt> nlopt_;

  // Underlying linear optimization object.
  PolynomialOptimization<N> poly_opt_;

  // Parameters for the nonlinear optimzation.
  NonlinearOptimizationParameters optimization_parameters_;

  // Holds the data for evaluating inequality constraints.
  std::vector<std::shared_ptr<ConstraintData> > inequality_constraints_;

  OptimizationInfo optimization_info_;
};

}  // namespace mav_trajectory_generation

namespace nlopt {
// Convenience function that turns nlopt's return values into something
// readable.
std::string returnValueToString(int return_value);
}  // namespace nlopt

#endif  // MAV_TRAJECTORY_GENERATION_POLYNOMIAL_OPTIMIZATION_NONLINEAR_H_

#include "mav_trajectory_generation/impl/polynomial_optimization_nonlinear_impl.h"
